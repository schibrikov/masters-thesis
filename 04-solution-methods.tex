
\section{Описание методов решения}

\subsection{Нейронная сеть}

% \addimg{malivar.tech_01_static_images.005}{0.4}{Шаг 1 - запись видео}{step_01_record}
% \addimg{malivar.tech_01_static_images.006}{0.4}{Шаг 2 - детектирование лица}{step_02_detect}
% \addimg{malivar.tech_01_static_images.007}{0.4}{Шаг 3 - замена лица}{step_03_swap}
% \addimg{malivar.tech_01_static_images.008}{0.4}{Шаг 4 - сегментация лица}{step_04_segmentation}
% \addimg{malivar.tech_01_static_images.009}{0.4}{Шаг 5 - наложение на исходное видео}{step_05_merging}
% \addimg{malivar.tech_01_static_images.010}{0.4}{Шаг 6 - super resolution}{step_06_super_resolution}
% \addimg{malivar.tech_01_static_images.011}{0.4}{Финальный результат}{step_07_final_result}

\noindent

\begin{figure}
	\includegraphics[width=0.5\linewidth]{malivar.tech_01_static_images.005}
	\includegraphics[width=0.5\linewidth]{malivar.tech_01_static_images.006}
	\includegraphics[width=0.5\linewidth]{malivar.tech_01_static_images.007}
	\includegraphics[width=0.5\linewidth]{malivar.tech_01_static_images.008}
	\includegraphics[width=0.5\linewidth]{malivar.tech_01_static_images.009}
	\includegraphics[width=0.5\linewidth]{malivar.tech_01_static_images.010}
	\includegraphics[width=\linewidth]{malivar.tech_01_static_images.011}
	\caption{Последовательность обработки видео}
\end{figure}

\subsection{Клиент-серверная архитектура фронтенда}

Для разработки внешней части приложения выбрана клиент-серверная архитектура.

Выполнение вычислительно сложных операций, необходимых для решения задачи, возможно на клиентских устройствах в очень ограниченном объеме и несет множество проблем, таких как необходимость держать устройство включенным, потеря

Такое решение позволяет производить вычислительно сложные операции на серверах, так же сохраняя там приватную информацию о системе.

\addimg{malivar_service_architecture}{0.6}{Схема архитектуры сервиса}{architecture_scheme}

\subsection{Инфраструктура}

В любой системе центральным вопросом инфраструктуры является расположение серверов. Под разработкой обычно подразумевается создание программного продукта, но когда дело касается разворачивания приложения в публичный доступ, возникает вопрос - покупать и располагать физические сервера у себя в компании или дата-центре или воспользоваться облачными провайдерами и получать необходимые мощности по подписке.

Рассмотрим некоторые особенности обоих вариантов.

Собственные сервера приобретаются один раз и могут стоить достаточно дешево, в сравнении с ежемесячными счетами от облачного провайдера. На первый взгляд из постоянных расходов они требуют лишь электричество и интернет. Но в деталях ситуация оказывается гораздо сложнее.

Собственные сервера требуют настройки и постоянного обслуживания, пример - обновления ПО. Для того, чтобы обеспечить непрерывную работы потребуются резервные интернет-каналы, запасной источник питания (например, ИБП).
Так же сервера отличаются от обычных компьютеров тем - они ориентированы на постоянную работу и имеют свои особенности. Например, шум и необходимость серьезного охлаждения. Обычно это проявляются в том, что для содержания своих серверов выделяют отдельную комнату - серверную.

Помимо собственно поддержки самого аппаратного обеспечения и операционных систем серверов, собственные сервера лишают возможности использования дополнительных услуг облачных провайдеров - управляемые (managed) сервисы, автоматическая репликация, в том числе геораспредленная, управление доступом и многое другое.

Если учитывать своимость обслуживания, собственные сервера могут оказаться гораздо дороже облачных услуг.

Облачные провайдеры, напротив, предоствляют максимально удобные, готовые и самоподдерживаемые сервисы, особенно при использовании не чистых виртуальных машин, а готовых сервисов, таких как управляемые базы данных, управляемый Kubernetes, файловое хранилище. Облачные провайдеры предоствляют автоматическое резервное копирование и обновление. Серьезным минусов использования "облаков" является так называемый vendor-lock - завязка на конкретного провайдера и невозможность (или очень высокая стоимость) переноса инфраструктуры от него. Это случается, если на проекте активно используются уникальные услуги, не предоставляемые или сильно отличающиеся у других провайдеров.

Для данного проекта было выбрано использования облачного провайдера Azure для размещения инфраструктуры. Это сервис от компании Microsoft. Он содержит огромное количество готовых сервисов и удобный веб-интерфейс для управления инфраструктурой.

Как целевая платформа для разработки приложений был выбран Kubernetes. Он имеет ряд очень существенных преимуществ по сравнению с работой с обычными серверами или виртуальными машинами.

\begin{itemize}
	\item Позволяет автоматически разворачивать сервера и подстраивать их количество под требования системы
	\item Универсален для всех облачных провайдеров и позволяет легко перенести свое приложение, в том числе на собственную инфраструктуру
	\item Предоставляет стандартизированный способ разворачивания приложений и сервисов
	\item Имеет огромное сообщество, множество open-source решений имеют готовые конфигурационные файлы для Kubernets
	\item Позволяет легко открывать доступ из вне к приложениям, при этом сохраняя их по умолчанию приватными
	\item Содержит инструменты для мониторинга и отладки приложений
\end{itemize}

\subsection{Хранение данных}

Для хранения пользователей, истории запросов, данных о состоянии обработки запросов, информации о подписках и многого другого была выбрана система управления базами данных PostgreSQL.

От других подобных решений она отличается полной бесплатностью и открытым исходным кодом, огромным сообществом, множеством возможностей и дополнений, работой "из коробки" с практически любыми языками и библиотеками. PostgreSQL - стандарт де-факто среди SQL баз данных для веб-приложений.

Так же исходя из специфики работы с мультимедиа в решении требуется файловое хранилище, позволяющее хранить промежуточные и финальные результаты обработки. Объектом хранения здесь являются бинарные файлы, представляющие собой фрагменты видео, целые видеофайлы, а так же фотографии лиц.

Рассмотрим различные опции:

\begin{itemize}
	\item База данных
	\item Файловая система
	\item Оперативное хранилище, например Redis
	\item Облачное хранилище (S3)
\end{itemize}

Современные СУБД и частности PostgreSQL позволяют хранить бинарные данные в обычных SQL таблицах. В PostgreSQL для этого существуют 2 опции - \textbf{Large Objects} и тип данных \texttt{bytea}.

К сожалению, эти опции не очень хорошо подходят для нашего cлучая.

Large Objects являются нестандартной возможностью и плохо поддерживаются различными клиентами. Так же они требуют явного удаления файла, потому что сами данные хранятся отдельно от таблицы, которой принадлежат.

bytea плохо подходит для больших файлов, т.к. не поддерживает стриминг, а значит при работе с видеофайлами требуется много оперативной памяти. В нашем случае файлы вполне могут иметь размер в несколько гигабайт и даже больше, а значит требования к серверу базы данных (как и к клиентскому приложению) были бы огромны.

Более того - обе опции очень малопрозводительны. Это очевидно, если исходить из того, что SQL базы данных совсем не ориентированы на хранение больших бинарных блоков. Производительность запросов в этом случае будет оставлять желать лучшего.

Файловая система, что неудивительно, отлично подходит для хранения файлов. Но в нашем случае имеет ряд критических недостатков. Во-первых, к диску может одновременно иметь доступ только одна машина (виртуальная или физическая), а значит провоцирует монолитную архитектуру сервиса, что невозможно в нашем случае. Во-вторых, файловая система не позволяет автоматически переносить данные на более медленные и дешевые СХД. В-третьих, нужно самому организовывать систему резервного копирования, чтобы не потерять данные.

Третий вариант - key-value системы хранения данных, подобные Redis. Они хранят данные в памяти, иногда сгружая в постоянное хранилище. Для данного проекта они так же имеют ряд серьезных ограничений. Такие системы не гарантируют надежность хранения данных, имеют плохую устойчивость к перезагрузкам. Они ориентированы на хранение данных в памяти, что плохо подходит для больших файлов.

Облачные файловые хранилища оказались лучшей опцией в нашем случае. Хранение большого обьема файлов в нем достаточно дешево, они гарантируют надежность хранения данных и их репликацию по необходимости. Обращение к файлам являются достаточно быстрыми по скорости, особенно учитывая колокацию с серверами приложений на мощностях облачного провайдера.

Таким образом, для хранения всех медиафайлов в процессе работы проекта было выбрано облачное хранилище, а конкретно \texttt{Azure Blob Storage}. Решения у различных облачных провайдеров в этой области очень похожи. Для проекта самым рациональным является выбор того сервиса, который относится к используемому облачному провайдеру.

\subsection{Предобработка данных}

Перед наложением лица видео требует дополнительной обработки исходя из требований к сервису.

Во-первых, пользователям предлагаются разные тарифные планы, при которых обработка видео требует различного количества ресурсов. Например, для пользователей бесплатной (пробной) версии доступна обработка видео разрешением до FullHD (1920х1080) и до 30 кадров в секунду. Такие ограничения позволяют сэкономить на времени обработки, т.к. нейронные сети быстрее работают с меньшим объемом данных. Назовем этот шаг ограничением качества видео.

Во-вторых, в требованиях к сервису мы определили необходимость ускорения обработки за счет распределенной обработки на нескольких серверах одновременно. Так, например, при наличии 10 свободных серверов, мы можем обработать пользовательское видео в 10 раз быстрее.

Самый эффективный способ распределить обработку видео на несколько потоков - поделить его на сегменты примерно одинаковой длины и запустить в очередь как обработку нескольких видео. Так сервера-обработчики смогут максимально быстро разобрать и выполнить все задачи по обработке.

В текущей версии ограничение качества не происходит на этапе предобработки данных, а вместо этого выполняется на этапе самой обработки, непосредственно перед передачей обрабатываемого сегмента в нейронную сеть.

Второй же шаг необходим. Задача состоит в том, чтобы поделить видео на сегменты примерно равной продолжительности, не потратив на это много времени. При этом после обработки эти сегменты должно быть возможно бесшовно склеить ровно так, как было в исходном видео. Еще одна задача этого этапа - максимально сохранить качество видео. Если ограничения на качество видео не накладываются, мы хотим чтобы пользователь получил результат максимально близкий к исходному видео по качеству. Так как мы ориентируемся на бизнес-пользователей, для которых это очень критично.

Так же разделение на сегменты является важной возможностью сервиса, сильно увеличивающей возможности для контроля обработки. Например, в случае неожиданной ошибки прогресс сможет быть сохранен с точностью до длины кусочка. Так же появляется возможность приоритезации обработок разных клиентов "на ходу". Во время долгой обработки бесплатного клиента, может быть загружено видео более приоритетного клиента. Тогда в случае коротких сегментов у нас будет возможность максимально быстро обработать приоритетное видео и затем вернуться к первому клиенту.

FFMpeg - утилита - швейцарский нож в мире обработки и перекодирования видео. Она содержит множество настроек и инструментов для практически любых задач в этой области. В частности, в ней есть необходимая нам возможность разделения видео на сегменты. Нужная нам опция называется /texttt{segment muxer}.

Для использования этой возможности нам необходимо включить в ffmpeg режим вывода segment опцией \texttt{\-f segment} и задать целевое время сегмента с помощью \texttt{-segment\_time <количество\_секунд>}. Мы используем 5 секунд на сегмент. Это хорошо подходит под среднюю длину видео, загружаемых нашими клиентами, которая не превышает 10-20 секунд.

\subsection{Очередь задач}

\subsection{Необходимая постобработка}